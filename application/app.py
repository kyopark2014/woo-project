import streamlit as st 
import logging
import sys
import os
import qa_agent.agent as qa
import mcp_agent.agent as mcp
import reflection_agent.agent as reflection
import chat
import asyncio

logging.basicConfig(
    level=logging.INFO,  # Default to INFO level
    format='%(filename)s:%(lineno)d | %(message)s',
    handlers=[
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger("streamlit")

os.environ["DEV"] = "true"  # Skip user confirmation of get_user_input

# title
st.set_page_config(page_title='Woo', page_icon=None, layout="centered", initial_sidebar_state="auto", menu_items=None)

mode_descriptions = {
    "Agent": [
        "MCPë¥¼ ë„êµ¬ë¡œ í™œìš©í•˜ëŠ” Agentë¥¼ ì´ìš©í•©ë‹ˆë‹¤."
    ],
    "QA Agent": [
        "ì£¼ì–´ì§„ ì§ˆë¬¸ìœ¼ë¡œ RAGë¥¼ ê²€ìƒ‰í•˜ê³  Test Caseë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    ],
    "QA Agent (Multi)": [
        "ë©€í‹° ì—ì´ì „íŠ¸ë¥¼ ì´ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì§ˆë¬¸ì—ì„œ QA í•­ëª©ì„ ì¶”ì¶œí•˜ê³  Test Caseë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    ],
    "QA Agent (Parallel)": [
        "ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì§ˆë¬¸ì—ì„œ QA í•­ëª©ì„ ì¶”ì¶œí•˜ê³  Test Caseë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
    ],
    "Reflection Agent": [
        "QA Agentì˜ ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤."
    ],
    "ì´ë¯¸ì§€ ë¶„ì„": [
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ]
}

with st.sidebar:
    st.title("ğŸ”® Menu")
    
    st.markdown(
        "Strandsì™€ MCPë¥¼ ì´ìš©í•˜ì—¬ ë˜‘ë˜‘í•œ Agentë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤." 
        "ìƒì„¸í•œ ì½”ë“œëŠ” [Github](https://github.com/kyopark2014/woo-project)ì„ ì°¸ì¡°í•˜ì„¸ìš”."
    )

    st.subheader("ğŸ± ëŒ€í™” í˜•íƒœ")
    
    # radio selection
    mode = st.radio(
        label="ì›í•˜ëŠ” ëŒ€í™” í˜•íƒœë¥¼ ì„ íƒí•˜ì„¸ìš”. ",options=["Agent", "QA Agent", "Reflection Agent", "QA Agent (Multi)", "QA Agent (Parallel)", "ì´ë¯¸ì§€ ë¶„ì„"], index=0
    )   
    st.info(mode_descriptions[mode][0])
    
    # model selection box
    modelName = st.selectbox(
        'ğŸ–Šï¸ ì‚¬ìš© ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”',
        (
            "Claude 4.5 Haiku",
            "Claude 4.5 Sonnet",
            "Claude 4.5 Opus",  
            "Claude 4 Opus", 
            "Claude 4 Sonnet", 
            "Claude 3.7 Sonnet", 
            "Claude 3.5 Sonnet", 
            "Claude 3.0 Sonnet", 
            "Claude 3.5 Haiku", 
            "OpenAI OSS 120B",
            "OpenAI OSS 20B",
            "Nova 2 Lite",
            "Nova Premier", 
            "Nova Pro", 
            "Nova Lite", 
            "Nova Micro",            
        ), index=0
    )
    
    chat.update(modelName)

    st.success(f"Connected to {modelName}", icon="ğŸ’š")
    clear_button = st.button("ëŒ€í™” ì´ˆê¸°í™”", key="clear")

    uploaded_file = None
    if mode=='ì´ë¯¸ì§€ ë¶„ì„':
        st.subheader("ğŸŒ‡ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ë¶„ì„ì„ ìœ„í•œ íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.", type=["png", "jpg", "jpeg"])

st.title('ğŸ”® '+ mode)

if clear_button or "messages" not in st.session_state:
    st.session_state.messages = []        
    
    st.session_state.greetings = False
    st.rerun()  

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.greetings = False

# Preview the uploaded image in the sidebar
file_name = ""
file_bytes = None
state_of_code_interpreter = False
if uploaded_file is not None and clear_button==False:
    logger.info(f"uploaded_file.name: {uploaded_file.name}")

    if uploaded_file and clear_button==False and mode == 'ì´ë¯¸ì§€ ë¶„ì„':
        st.image(uploaded_file, caption="ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°", use_container_width=True)

        file_name = uploaded_file.name
        file_bytes = uploaded_file.getvalue()    

# Display chat messages from history on app rerun
def display_chat_messages() -> None:
    """Print message history"""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

display_chat_messages()

# Greet user
if not st.session_state.greetings:
    with st.chat_message("assistant"):
        intro = "ì•„ë§ˆì¡´ ë² ë“œë½ì„ ì´ìš©í•˜ì—¬ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. Agentë¥¼ ì´ìš©í•´ í–¥ìƒëœ ëŒ€í™”ë¥¼ ì¦ê¸°ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        st.markdown(intro)
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": intro})
        st.session_state.greetings = True

if clear_button or "messages" not in st.session_state:
    st.session_state.messages = []        
    uploaded_file = None
    
    st.session_state.greetings = False
    chat.initiate()
    st.rerun()    

# Always show the chat input
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”."):
    with st.chat_message("user"):  # display user message in chat message container
        st.markdown(prompt)

    st.session_state.messages.append({"role": "user", "content": prompt})  # add user message to chat history
    prompt = prompt.replace('"', "").replace("'", "")
    logger.info(f"prompt: {prompt}")

    with st.chat_message("assistant"):        
        sessionState = ""
        response = ""
        
        with st.status("thinking...", expanded=True, state="running") as status:            
            if mode == 'Agent':            
                containers = {
                    "tools": st.empty(),
                    "status": st.empty(),
                    "notification": [st.empty() for _ in range(500)]
                }
                
                # prompt = "Doc Searchë¥¼ ì´ìš©í•´ ë‚´ ë¬¸ì„œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."
                response = asyncio.run(mcp.run_agent(query=prompt, containers=containers))
            elif mode == 'QA Agent':            
                containers = {
                    "tools": st.empty(),
                    "status": st.empty(),
                    "notification": [st.empty() for _ in range(500)]
                }
                #query = "9-2. í”½ì—…í•„í„° offì¼ì‹œ"
                response = asyncio.run(qa.run_agent(query=prompt, system_prompt=None, historyMode=False, containers=containers))

            elif mode == 'Reflection Agent':
                containers = {
                    "tools": st.empty(),
                    "status": st.empty(),
                    "notification": [st.empty() for _ in range(500)]
                }
                response = asyncio.run(reflection.run_agent(query=prompt, containers=containers))

            elif mode == 'QA Agent (Multi)':
                containers = {
                    "tools": st.empty(),
                    "status": st.empty(),
                    "notification": [st.empty() for _ in range(500)]
                }
                response = asyncio.run(mcp.run_multi_agent(query=prompt, containers=containers))

            elif mode == 'QA Agent (Parallel)':
                containers = {
                    "tools": st.empty(),
                    "status": st.empty(),
                    "notification": [st.empty() for _ in range(500)]
                }
                response = asyncio.run(mcp.run_parallel_agent(query=prompt, containers=containers))

            elif mode == "ì´ë¯¸ì§€ ë¶„ì„":
                if uploaded_file is None or uploaded_file == "":
                    st.error("íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
                    st.stop()

                else:
                    summary = chat.summarize_image(file_bytes, prompt, st)
                    st.write(summary)

        st.session_state.messages.append({
            "role": "assistant", 
            "content": response
        })
            